// Copyright 2021 The Kubeflow Authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// This file was autogenerated by go-to-protobuf. Do not edit it manually!

syntax = "proto2";

package github.com.kubeflow.training_operator.pkg.apis.pytorch.v1;

import "github.com/kubeflow/common/pkg/apis/common/v1/generated.proto";
import "k8s.io/api/autoscaling/v2beta2/generated.proto";
import "k8s.io/apimachinery/pkg/apis/meta/v1/generated.proto";
import "k8s.io/apimachinery/pkg/runtime/schema/generated.proto";
// import "sigs.k8s.io/controller-runtime/pkg/scheme/generated.proto";

// Package-wide variables from generator "generated".
option go_package = "v1";

message ElasticPolicy {
  // minReplicas is the lower limit for the number of replicas to which the training job
  // can scale down.  It defaults to null.
  // +optional
  optional int32 minReplicas = 1;

  // upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than MinReplicas, defaults to null.
  // +optional
  optional int32 maxReplicas = 2;

  optional string rdzvBackend = 3;

  optional int32 rdzvPort = 4;

  optional string rdzvHost = 5;

  optional string rdzvId = 6;

  // RDZVConf contains additional rendezvous configuration (<key1>=<value1>,<key2>=<value2>,...).
  repeated RDZVConf rdzvConf = 7;

  // Start a local standalone rendezvous backend that is represented by a C10d TCP store
  // on port 29400. Useful when launching single-node, multi-worker job. If specified
  // --rdzv_backend, --rdzv_endpoint, --rdzv_id are auto-assigned; any explicitly set values
  // are ignored.
  optional bool standalone = 8;

  // Number of workers per node; supported values: [auto, cpu, gpu, int].
  optional int32 nProcPerNode = 9;

  optional int32 maxRestarts = 10;

  // Metrics contains the specifications which are used to calculate the
  // desired replica count (the maximum replica count across all metrics will
  // be used).  The desired replica count is calculated with multiplying the
  // ratio between the target value and the current value by the current
  // number of pods. Ergo, metrics used must decrease as the pod count is
  // increased, and vice-versa.  See the individual metric source types for
  // more information about how each type of metric must respond.
  // If not set, the HPA will not be created.
  // +optional
  repeated k8s.io.api.autoscaling.v2beta2.MetricSpec metrics = 11;
}

// PyTorchJob Represents a PyTorchJob resource.
message PyTorchJob {
  optional k8s.io.apimachinery.pkg.apis.meta.v1.ObjectMeta metadata = 1;

  // Specification of the desired state of the PyTorchJob.
  optional PyTorchJobSpec spec = 2;

  // Most recently observed status of the PyTorchJob.
  // Read-only (modified by the system).
  optional github.com.kubeflow.common.pkg.apis.common.v1.JobStatus status = 3;
}

// PyTorchJobList is a list of PyTorchJobs.
message PyTorchJobList {
  // Standard list metadata.
  optional k8s.io.apimachinery.pkg.apis.meta.v1.ListMeta metadata = 1;

  // List of PyTorchJobs.
  repeated PyTorchJob items = 2;
}

// PyTorchJobSpec is a desired state description of the PyTorchJob.
message PyTorchJobSpec {
  // RunPolicy encapsulates various runtime policies of the distributed training
  // job, for example how to clean up resources and how long the job can stay
  // active.
  // +kubebuilder:validation:Optional
  optional github.com.kubeflow.common.pkg.apis.common.v1.RunPolicy runPolicy = 1;

  optional ElasticPolicy elasticPolicy = 2;

  // A map of PyTorchReplicaType (type) to ReplicaSpec (value). Specifies the PyTorch cluster configuration.
  // For example,
  //   {
  //     "Master": PyTorchReplicaSpec,
  //     "Worker": PyTorchReplicaSpec,
  //   }
  map<string, github.com.kubeflow.common.pkg.apis.common.v1.ReplicaSpec> pytorchReplicaSpecs = 3;
}

message RDZVConf {
  optional string key = 1;

  optional string value = 2;
}

